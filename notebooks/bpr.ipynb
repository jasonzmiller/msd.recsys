{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bbe7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926ce600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../datasets/clean_df.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b919a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user id and song id to numerical ids\n",
    "df['user_id'] = df['user'].astype('category').cat.codes\n",
    "df['song_id'] = df['song'].astype('category').cat.codes\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Create lookup frame so we can get the 'Song - Artist' later\n",
    "item_lookup = df[['song_id','Song - Artist']].drop_duplicates()\n",
    "item_lookup['song_id'] = item_lookup['song_id'].astype(str)\n",
    "\n",
    "# Drop 'user' and 'song' and 'Song - Artist'\n",
    "df = df.drop(['user','song','Song - Artist'], axis=1)\n",
    "\n",
    "# Create lists of all users, songs, and counts\n",
    "users = list(np.sort(df['user_id'].unique()))\n",
    "songs = list(np.sort(df['song_id'].unique()))\n",
    "play_counts = list(np.sort(df['count']))\n",
    "\n",
    "# Get the rows and columns for our matrix\n",
    "user_ = df['user_id'].astype(float)\n",
    "item_ = df['song_id'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278de9f4",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "The main idea here is to see if our model recommends any of the songs a user has listened to many times. We know these song items are most likely positive (well-liked by the user), so we can measure goodness of the model based on how many of these positive items it recommends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea46c8",
   "metadata": {},
   "source": [
    "#### Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ca2349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87253, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the users that have listened to any song more than 4 times\n",
    "min_listens = 4\n",
    "tmp_test = df[df['count'] > min_listens]\n",
    "tmp_test = (\n",
    "        tmp_test.groupby('user_id')['song_id'].count()\n",
    "    ).reset_index().rename({'song_id':'records'}, axis=1)\n",
    "tmp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5119c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_records = 4\n",
    "conditions = (df['user_id'].isin(tmp_test[tmp_test['records'] > min_records].user_id) & (df['count'] > min_listens))\n",
    "df_test = df[conditions].groupby('user_id').head(2).reset_index()\n",
    "del df_test['index']\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503f05c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_test = df_test.groupby('user_id')['song_id'].agg(list).reset_index()\n",
    "ground_truth_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a4b21d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3128</td>\n",
       "      <td>[2918, 964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3694</td>\n",
       "      <td>[3548, 964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5314</td>\n",
       "      <td>[1424, 1918]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5496</td>\n",
       "      <td>[2210, 2924]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7070</td>\n",
       "      <td>[2994, 1424]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       song_id\n",
       "0     3128   [2918, 964]\n",
       "1     3694   [3548, 964]\n",
       "2     5314  [1424, 1918]\n",
       "3     5496  [2210, 2924]\n",
       "4     7070  [2994, 1424]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6126768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>82030</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>135080</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>235886</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>257077</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>162425</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  user_id  song_id\n",
       "0     13    82030     3269\n",
       "1      7   135080     3269\n",
       "2      7   235886     3269\n",
       "3     17   257077     3269\n",
       "4      5   162425     3269"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fb348",
   "metadata": {},
   "source": [
    "#### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296a0712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772233, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df, df_test]).drop_duplicates(keep=False)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79326130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87253, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_train = df_train[df_train['count'] > 4].groupby('user_id')['song_id'].agg(list).reset_index()\n",
    "ground_truth_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081950",
   "metadata": {},
   "source": [
    "#### Building triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61feb6e4",
   "metadata": {},
   "source": [
    "Need to find users that:\n",
    "- Have 3 positive items (listen count > 1)\n",
    "    - 2 positive items extracted for testing\n",
    "    - 1 positive item used for triplet\n",
    "- Have 1 negative item (listen count == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2248ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records_for_user = pd.DataFrame(\n",
    "    df_train.groupby(['user_id'])['song_id'].count().reset_index()\n",
    ").rename({'song_id' : 'records'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b357fa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80513"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_users = num_records_for_user[num_records_for_user['records'] > 2]['user_id'].tolist()\n",
    "len(candidate_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c193408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users processed. Found 0 qualified users. 80513 users remaining.\n",
      "10000 users processed. Found 6823 qualified users. 70513 users remaining.\n",
      "20000 users processed. Found 13617 qualified users. 60513 users remaining.\n",
      "30000 users processed. Found 20351 qualified users. 50513 users remaining.\n",
      "40000 users processed. Found 27137 qualified users. 40513 users remaining.\n",
      "50000 users processed. Found 33920 qualified users. 30513 users remaining.\n",
      "60000 users processed. Found 40736 qualified users. 20513 users remaining.\n",
      "70000 users processed. Found 47548 qualified users. 10513 users remaining.\n",
      "80000 users processed. Found 54346 qualified users. 513 users remaining.\n",
      "Building DataFrame...\n",
      "CPU times: user 9min 25s, sys: 26.6 s, total: 9min 51s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_triplets = pd.DataFrame(columns=['user_id','pos_song','neg_song'])\n",
    "\n",
    "data = []\n",
    "unqualified_users = []\n",
    "threshold = 1\n",
    "\n",
    "for i, user in enumerate(candidate_users):\n",
    "    if ( i % 10_000 == 0 ):\n",
    "        print(f'{i} users processed. ' +\n",
    "              f'Found {i - len(unqualified_users)} qualified users. ' +\n",
    "              f'{len(candidate_users) - i} users remaining.')\n",
    "    pos_songs = df_train[(df_train['user_id'] == user) & \n",
    "                              (df_train['count'] > threshold)]['song_id'].values\n",
    "    neg_songs = df_train[(df_train['user_id'] == user) &\n",
    "                              (df_train['count'] == threshold)]['song_id'].values\n",
    "    \n",
    "    if ( len(pos_songs) == 0 or len(neg_songs) == 0 ):\n",
    "        unqualified_users.append(user)\n",
    "        continue\n",
    "        \n",
    "    for pos in pos_songs:\n",
    "        for neg in neg_songs:\n",
    "            data.append({\n",
    "                'user_id' : user,\n",
    "                'pos_song' : pos,\n",
    "                'neg_song' : neg\n",
    "            })\n",
    "            \n",
    "print('Building DataFrame...')\n",
    "df_triplets = df_triplets.append(data, ignore_index=True)\n",
    "df_triplets['user_id'] = df_triplets['user_id'].astype(float)\n",
    "df_triplets['pos_song'] = df_triplets['pos_song'].astype(float)\n",
    "df_triplets['neg_song'] = df_triplets['neg_song'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b7a871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((286383, 3), (772233, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triplets.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c94453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pos_song</th>\n",
       "      <th>neg_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>3548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>1894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>3548.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  pos_song  neg_song\n",
       "0      1.0    2370.0    3548.0\n",
       "1      1.0    2370.0    2818.0\n",
       "2      4.0     366.0    1894.0\n",
       "3      4.0    2580.0    1894.0\n",
       "4      6.0     639.0    3548.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triplets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0e982",
   "metadata": {},
   "source": [
    "### BPR NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6925a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers = df['user_id'].nunique()\n",
    "nsongs = df['song_id'].nunique()\n",
    "unique_songs = list(df['song_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5a260",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a93f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_predict(model: Model, user_id: int, song_ids: list, user_layer='user_embedding', item_layer='item_embedding'):\n",
    "    user_vector = model.get_layer(user_layer).get_weights()[0][user_id]\n",
    "    item_matrix = model.get_layer(item_layer).get_weights()[0][song_ids]\n",
    "    \n",
    "    scores = np.dot(user_vector, item_matrix.T)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8658f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def identity_loss(_, y_pred):\n",
    "    return tf.math.reduce_mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab5be84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def bpr_triplet_loss(X: dict):\n",
    "    \"\"\"\n",
    "    Calculate triplet loss - as higher the difference between positive interactions\n",
    "    and negative interactions as better\n",
    "\n",
    "    :param X: X contains the user input, positive item input, negative item input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    positive_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, positive_item_latent), axis=-1, keepdims=True)\n",
    "    negative_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, negative_item_latent), axis=-1, keepdims=True)\n",
    "\n",
    "    return tf.math.subtract(tf.constant(1.0), tf.sigmoid(tf.math.subtract(positive_interactions, negative_interactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccef2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_shape(shapes):\n",
    "    return shapes[0]\n",
    "    \n",
    "\n",
    "def build_model(num_users: int, num_items: int, latent_dim: int) -> Model:\n",
    "    \"\"\"\n",
    "    Build a model for Bayesian personalized ranking\n",
    "\n",
    "    :param num_users: a number of the unique users\n",
    "    :param num_items: a number of the unique movies\n",
    "    :param latent_dim: vector length for the latent representation\n",
    "    :return: Model\n",
    "    \"\"\"\n",
    "    user_input = Input((1,), name='user_input')\n",
    "\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "    # One embedding layer is shared between positive and negative items\n",
    "    item_embedding_layer = Embedding(num_items, latent_dim, name='item_embedding', input_length=1)\n",
    "\n",
    "    positive_item_embedding = Flatten()(item_embedding_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_embedding_layer(negative_item_input))\n",
    "\n",
    "    user_embedding = Embedding(num_users, latent_dim, name='user_embedding', input_length=1)(user_input)\n",
    "    user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "    triplet_loss = Lambda(bpr_triplet_loss, output_shape=out_shape)([positive_item_embedding,\n",
    "                                                             negative_item_embedding,\n",
    "                                                             user_embedding])\n",
    "\n",
    "    model = Model(inputs=[positive_item_input, negative_item_input, user_input], outputs=triplet_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd06c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "#  HYPERPARAMS\n",
    "#---------------\n",
    "latent_dim = 350\n",
    "batch_size = 256\n",
    "num_epochs = 3\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b00e513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positive_item_input (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_item_input (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 350)       1286250     positive_item_input[0][0]        \n",
      "                                                                 negative_item_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 350)       146388200   user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 350)          0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 350)          0           item_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 350)          0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 147,674,450\n",
      "Trainable params: 147,674,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(nusers, nsongs, latent_dim)\n",
    "model.compile(loss=identity_loss, optimizer=Adam(learning_rate=lr))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a217905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1119/1119 [==============================] - 2157s 2s/step - loss: 0.1392\n",
      "Epoch 2/3\n",
      "1119/1119 [==============================] - 31840s 28s/step - loss: 2.3320e-04\n",
      "Epoch 3/3\n",
      "1119/1119 [==============================] - 2109s 2s/step - loss: 6.0894e-05\n",
      "CPU times: user 2h 46min 37s, sys: 1h 42min 39s, total: 4h 29min 16s\n",
      "Wall time: 10h 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = {\n",
    "    'user_input': tf.convert_to_tensor(df_triplets['user_id']),\n",
    "    'positive_item_input': tf.convert_to_tensor(df_triplets['pos_song']),\n",
    "    'negative_item_input': tf.convert_to_tensor(df_triplets['neg_song'])\n",
    "}\n",
    "\n",
    "hist = model.fit(X, \n",
    "          tf.ones(df_triplets.shape[0]), \n",
    "          batch_size=batch_size,\n",
    "          verbose=1,\n",
    "          epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e610a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/bpr_LOCAL_e3/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/bpr_LOCAL_e3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "174cd28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f482ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = hist.history['loss']\n",
    "# val_loss = hist.history['val_loss']\n",
    "plt.plot(train_loss, color='r', label='Train Loss')\n",
    "# plt.plot(val_loss, color='b', label='Validation Loss')\n",
    "plt.title(\"Train and Validation Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aede3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_auc(model: Model, ground_truth: Dict[int, list], items: list) -> float:\n",
    "    \"\"\"\n",
    "    Measure AUC for model and ground truth for all items\n",
    "    \n",
    "    :param model: \n",
    "    :param ground_truth: dictionary of the users and the high ranked songs for the specific user\n",
    "    :param items: a list of the all available songs\n",
    "    :return: AUC\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_items = len(items)\n",
    "    scores = []\n",
    "\n",
    "    for i, (user_id, true_item_ids) in enumerate(ground_truth):\n",
    "        if ( i > 0 and i % 1_000 == 0 ):\n",
    "            print(f'{i} items processed. {len(ground_truth) - i} more items to process. Current AUC: {sum(scores) / len(scores)}')\n",
    "\n",
    "        predictions = bpr_predict(model, user_id, items)\n",
    "        grnd = np.zeros(number_of_items, dtype=np.int32)\n",
    "\n",
    "        for p in true_item_ids:\n",
    "            index = items.index(p)\n",
    "            grnd[index] = 1\n",
    "\n",
    "        if true_item_ids:\n",
    "            scores.append(roc_auc_score(grnd, predictions))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e07ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision_k(model: Model, \n",
    "                           ground_truth: Dict[int, list], \n",
    "                           items: list, \n",
    "                           k=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate mean average precision per user\n",
    "\n",
    "    :param model: \n",
    "    :param ground_truth: dictionary of the users and the high ranked songs for the specific user\n",
    "    :param items: a list of the all available songs\n",
    "    :param k: top N recommendations per user\n",
    "    :return: mean eavarage precission\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i, (user, actual) in enumerate(ground_truth):\n",
    "        if ( i > 0 and i % 1_000 == 0 ):\n",
    "            print(f'{i} items processed. {len(ground_truth) - i} more items to process. Current MAP@K {np.mean(scores)}')\n",
    "            \n",
    "        predictions = bpr_predict(model, user, items)\n",
    "        predictions = dict(zip(items, predictions))\n",
    "        predictions = sorted(predictions.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "        predictions = list(OrderedDict(predictions).keys())\n",
    "\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(predictions):\n",
    "            if p in actual:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "\n",
    "        score = score / min(len(actual), k)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01d29d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "1000 items processed. 86253 more items to process. Current AUC: 0.6276244361516711\n",
      "2000 items processed. 85253 more items to process. Current AUC: 0.6232050987211324\n",
      "3000 items processed. 84253 more items to process. Current AUC: 0.6188337168530617\n",
      "4000 items processed. 83253 more items to process. Current AUC: 0.6167326126955692\n",
      "5000 items processed. 82253 more items to process. Current AUC: 0.6158422564932029\n",
      "6000 items processed. 81253 more items to process. Current AUC: 0.6154123491009121\n",
      "7000 items processed. 80253 more items to process. Current AUC: 0.6158405896012885\n",
      "8000 items processed. 79253 more items to process. Current AUC: 0.6150546440488502\n",
      "9000 items processed. 78253 more items to process. Current AUC: 0.616756443599432\n",
      "10000 items processed. 77253 more items to process. Current AUC: 0.6153022116491672\n",
      "11000 items processed. 76253 more items to process. Current AUC: 0.6145197035777192\n",
      "12000 items processed. 75253 more items to process. Current AUC: 0.6138751152212513\n",
      "13000 items processed. 74253 more items to process. Current AUC: 0.6137255013979758\n",
      "14000 items processed. 73253 more items to process. Current AUC: 0.6130227956273839\n",
      "15000 items processed. 72253 more items to process. Current AUC: 0.6137211177915164\n",
      "16000 items processed. 71253 more items to process. Current AUC: 0.6135838967625025\n",
      "17000 items processed. 70253 more items to process. Current AUC: 0.6142336105476637\n",
      "18000 items processed. 69253 more items to process. Current AUC: 0.6142023807627135\n",
      "19000 items processed. 68253 more items to process. Current AUC: 0.6149357779274218\n",
      "20000 items processed. 67253 more items to process. Current AUC: 0.61491617147452\n",
      "21000 items processed. 66253 more items to process. Current AUC: 0.6140260847942519\n",
      "22000 items processed. 65253 more items to process. Current AUC: 0.6136384289552421\n",
      "23000 items processed. 64253 more items to process. Current AUC: 0.6133947387716253\n",
      "24000 items processed. 63253 more items to process. Current AUC: 0.6136826360975991\n",
      "25000 items processed. 62253 more items to process. Current AUC: 0.6132113651265628\n",
      "26000 items processed. 61253 more items to process. Current AUC: 0.6127197121225517\n",
      "27000 items processed. 60253 more items to process. Current AUC: 0.6124732985398373\n",
      "28000 items processed. 59253 more items to process. Current AUC: 0.6126628889950452\n",
      "29000 items processed. 58253 more items to process. Current AUC: 0.6131711718462183\n",
      "30000 items processed. 57253 more items to process. Current AUC: 0.6130811615828357\n",
      "31000 items processed. 56253 more items to process. Current AUC: 0.6128458249614381\n",
      "32000 items processed. 55253 more items to process. Current AUC: 0.6130555308606144\n",
      "33000 items processed. 54253 more items to process. Current AUC: 0.6134248161128791\n",
      "34000 items processed. 53253 more items to process. Current AUC: 0.6137394116359678\n",
      "35000 items processed. 52253 more items to process. Current AUC: 0.6139174629908822\n",
      "36000 items processed. 51253 more items to process. Current AUC: 0.6140592735763047\n",
      "37000 items processed. 50253 more items to process. Current AUC: 0.6139817957237106\n",
      "38000 items processed. 49253 more items to process. Current AUC: 0.613783707560025\n",
      "39000 items processed. 48253 more items to process. Current AUC: 0.6138552930697004\n",
      "40000 items processed. 47253 more items to process. Current AUC: 0.6133782162651127\n",
      "41000 items processed. 46253 more items to process. Current AUC: 0.6132255369887771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6075eb93f1dc>\u001b[0m in \u001b[0;36mfull_auc\u001b[0;34m(model, ground_truth, items)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i} items processed. {len(ground_truth) - i} more items to process. Current AUC: {sum(scores) / len(scores)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpr_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mgrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-60869984b3e8>\u001b[0m in \u001b[0;36mbpr_predict\u001b[0;34m(model, user_id, song_ids, user_layer, item_layer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbpr_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_embedding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mitem_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1829\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0moutput_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m   \"\"\"\n\u001b[1;32m   3743\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3745\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3742\u001b[0m   \"\"\"\n\u001b[1;32m   3743\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3745\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    630\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \"\"\"\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[1;32m    673\u001b[0m           self._handle, self._dtype)\n\u001b[1;32m    674\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    468\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    471\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[1;32m    472\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('TRAIN:')\n",
    "print(f'AUC train: {full_auc(model, ground_truth_train.values, unique_songs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af175cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 items processed. 86253 more items to process. Current MAP@K 0.18470773809523808\n",
      "2000 items processed. 85253 more items to process. Current MAP@K 0.17971066468253968\n",
      "3000 items processed. 84253 more items to process. Current MAP@K 0.1704055224867725\n",
      "4000 items processed. 83253 more items to process. Current MAP@K 0.1693814236111111\n",
      "5000 items processed. 82253 more items to process. Current MAP@K 0.1693366468253968\n",
      "6000 items processed. 81253 more items to process. Current MAP@K 0.169764666005291\n",
      "7000 items processed. 80253 more items to process. Current MAP@K 0.17182552437641724\n",
      "8000 items processed. 79253 more items to process. Current MAP@K 0.17151558779761905\n",
      "9000 items processed. 78253 more items to process. Current MAP@K 0.17419035493827162\n",
      "10000 items processed. 77253 more items to process. Current MAP@K 0.17431016865079366\n",
      "11000 items processed. 76253 more items to process. Current MAP@K 0.17348275613275613\n",
      "12000 items processed. 75253 more items to process. Current MAP@K 0.17391367394179894\n",
      "13000 items processed. 74253 more items to process. Current MAP@K 0.17413773656898657\n",
      "14000 items processed. 73253 more items to process. Current MAP@K 0.17481996173469386\n",
      "15000 items processed. 72253 more items to process. Current MAP@K 0.17528429232804235\n",
      "16000 items processed. 71253 more items to process. Current MAP@K 0.17526715649801589\n",
      "17000 items processed. 70253 more items to process. Current MAP@K 0.1757498657796452\n",
      "18000 items processed. 69253 more items to process. Current MAP@K 0.17625780974426805\n",
      "19000 items processed. 68253 more items to process. Current MAP@K 0.1760921835839599\n",
      "20000 items processed. 67253 more items to process. Current MAP@K 0.1760241121031746\n",
      "21000 items processed. 66253 more items to process. Current MAP@K 0.17520598544973545\n",
      "22000 items processed. 65253 more items to process. Current MAP@K 0.17575588774651274\n",
      "23000 items processed. 64253 more items to process. Current MAP@K 0.17561737261329652\n",
      "24000 items processed. 63253 more items to process. Current MAP@K 0.17601761188271606\n",
      "25000 items processed. 62253 more items to process. Current MAP@K 0.17561894708994708\n",
      "26000 items processed. 61253 more items to process. Current MAP@K 0.17520695461945462\n",
      "27000 items processed. 60253 more items to process. Current MAP@K 0.17452254801097394\n",
      "28000 items processed. 59253 more items to process. Current MAP@K 0.17397098450491308\n",
      "29000 items processed. 58253 more items to process. Current MAP@K 0.174266109873068\n",
      "30000 items processed. 57253 more items to process. Current MAP@K 0.17404704774502394\n",
      "31000 items processed. 56253 more items to process. Current MAP@K 0.17411185112037644\n",
      "32000 items processed. 55253 more items to process. Current MAP@K 0.174060155954743\n",
      "33000 items processed. 54253 more items to process. Current MAP@K 0.17467335829954878\n",
      "34000 items processed. 53253 more items to process. Current MAP@K 0.17474821692565917\n",
      "35000 items processed. 52253 more items to process. Current MAP@K 0.17457779734909837\n",
      "36000 items processed. 51253 more items to process. Current MAP@K 0.17467051616171161\n",
      "37000 items processed. 50253 more items to process. Current MAP@K 0.17454262898102185\n",
      "38000 items processed. 49253 more items to process. Current MAP@K 0.17391088547261008\n",
      "39000 items processed. 48253 more items to process. Current MAP@K 0.17424783502432314\n",
      "40000 items processed. 47253 more items to process. Current MAP@K 0.1741297939106198\n",
      "41000 items processed. 46253 more items to process. Current MAP@K 0.17420777657946648\n",
      "42000 items processed. 45253 more items to process. Current MAP@K 0.1741583732633265\n",
      "43000 items processed. 44253 more items to process. Current MAP@K 0.17402738303977924\n",
      "44000 items processed. 43253 more items to process. Current MAP@K 0.17392220021215557\n",
      "45000 items processed. 42253 more items to process. Current MAP@K 0.17391428183001595\n",
      "46000 items processed. 41253 more items to process. Current MAP@K 0.17378167321880444\n",
      "47000 items processed. 40253 more items to process. Current MAP@K 0.1736594736535276\n",
      "48000 items processed. 39253 more items to process. Current MAP@K 0.17369034854103682\n",
      "49000 items processed. 38253 more items to process. Current MAP@K 0.17349862374087957\n",
      "50000 items processed. 37253 more items to process. Current MAP@K 0.17340316713907786\n",
      "51000 items processed. 36253 more items to process. Current MAP@K 0.17341177684036577\n",
      "52000 items processed. 35253 more items to process. Current MAP@K 0.17362688537487642\n",
      "53000 items processed. 34253 more items to process. Current MAP@K 0.17365742407550022\n",
      "54000 items processed. 33253 more items to process. Current MAP@K 0.17379065666904622\n",
      "55000 items processed. 32253 more items to process. Current MAP@K 0.17393228397924826\n",
      "56000 items processed. 31253 more items to process. Current MAP@K 0.1737485406712288\n",
      "57000 items processed. 30253 more items to process. Current MAP@K 0.17382019441792312\n",
      "58000 items processed. 29253 more items to process. Current MAP@K 0.17378482297612532\n",
      "59000 items processed. 28253 more items to process. Current MAP@K 0.17365488112853428\n",
      "60000 items processed. 27253 more items to process. Current MAP@K 0.17374737473230034\n",
      "61000 items processed. 26253 more items to process. Current MAP@K 0.17407779442833599\n",
      "62000 items processed. 25253 more items to process. Current MAP@K 0.17419029682661596\n",
      "63000 items processed. 24253 more items to process. Current MAP@K 0.17409347427683594\n",
      "64000 items processed. 23253 more items to process. Current MAP@K 0.1739549105666572\n",
      "65000 items processed. 22253 more items to process. Current MAP@K 0.17370776236990523\n",
      "66000 items processed. 21253 more items to process. Current MAP@K 0.17385344832966854\n",
      "67000 items processed. 20253 more items to process. Current MAP@K 0.1738585763219052\n",
      "68000 items processed. 19253 more items to process. Current MAP@K 0.1736916259698324\n",
      "69000 items processed. 18253 more items to process. Current MAP@K 0.1736376525545806\n",
      "70000 items processed. 17253 more items to process. Current MAP@K 0.17382050184915235\n",
      "71000 items processed. 16253 more items to process. Current MAP@K 0.1739464706359852\n",
      "72000 items processed. 15253 more items to process. Current MAP@K 0.1740282656866759\n",
      "73000 items processed. 14253 more items to process. Current MAP@K 0.17438534659449775\n",
      "74000 items processed. 13253 more items to process. Current MAP@K 0.17430681767226408\n",
      "75000 items processed. 12253 more items to process. Current MAP@K 0.1743358696271101\n",
      "76000 items processed. 11253 more items to process. Current MAP@K 0.17422777182291044\n",
      "77000 items processed. 10253 more items to process. Current MAP@K 0.17418224520471967\n",
      "78000 items processed. 9253 more items to process. Current MAP@K 0.17421651671851074\n",
      "79000 items processed. 8253 more items to process. Current MAP@K 0.17419371873714323\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b972f2c38931>\u001b[0m in \u001b[0;36mmean_average_precision_k\u001b[0;34m(model, ground_truth, items, k)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i} items processed. {len(ground_truth) - i} more items to process. Current MAP@K {np.mean(scores)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpr_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-60869984b3e8>\u001b[0m in \u001b[0;36mbpr_predict\u001b[0;34m(model, user_id, song_ids, user_layer, item_layer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbpr_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_embedding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mitem_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1829\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0moutput_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m   \"\"\"\n\u001b[1;32m   3743\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3745\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3742\u001b[0m   \"\"\"\n\u001b[1;32m   3743\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3745\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    630\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Mean average precision train: {mean_average_precision_k(model, ground_truth_train.values, unique_songs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9031210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "AUC test: 0.48179376658668577\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Mean average precision test: 0.01246754932502596\n",
      "CPU times: user 3min 2s, sys: 2min 42s, total: 5min 44s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('TEST:')\n",
    "print(f'AUC test: {full_auc(model, ground_truth_test.values, unique_songs)}')\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print(f'Mean average precision test: {mean_average_precision_k(model, ground_truth_test.values, unique_songs)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
