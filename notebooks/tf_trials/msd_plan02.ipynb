{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40663ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5b295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./datasets/clean_df.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad347575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772661, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b24134",
   "metadata": {},
   "source": [
    "https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebd8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'user' : df['user'].to_numpy(),\n",
    "                'song' : df['song'].to_numpy(),\n",
    "                'Song - Artist' : df['Song - Artist'].to_numpy(),\n",
    "                'count' : df['count'].to_numpy()\n",
    "            }\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the basic features.\n",
    "listens = dataset.map(lambda x: {\n",
    "    'song' : x['song'],\n",
    "    'user' : x['user']\n",
    "})\n",
    "\n",
    "songs = dataset.map(lambda x: x['song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6f77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(dataset.map(lambda x: x['user']))\n",
    "\n",
    "song_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "song_ids_vocabulary.adapt(dataset.map(lambda x: x['song']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bced6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSongModel(tfrs.Model):\n",
    "    # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "    # these are still plain Keras Models.\n",
    "\n",
    "    def __init__(self,\n",
    "                 user_model: tf.keras.Model,\n",
    "                 song_model: tf.keras.Model,\n",
    "                 task: tfrs.tasks.Retrieval):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set up user and movie representations.\n",
    "        self.user_model = user_model\n",
    "        self.song_model = song_model\n",
    "\n",
    "        # Set up a retrieval task.\n",
    "        self.task = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # Define how the loss is computed.\n",
    "\n",
    "        user_embeddings = self.user_model(features['user'])\n",
    "        song_embeddings = self.song_model(features['song'])\n",
    "\n",
    "        return self.task(user_embeddings, song_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752931a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "song_model = tf.keras.Sequential([\n",
    "    song_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(song_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    songs.batch(128).map(song_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28d620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = UserSongModel(user_model, song_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "  2/378 [..............................] - ETA: 8:33:59 - factorized_top_k/top_1_categorical_accuracy: 0.0691 - factorized_top_k/top_5_categorical_accuracy: 0.0696 - factorized_top_k/top_10_categorical_accuracy: 0.0696 - factorized_top_k/top_50_categorical_accuracy: 0.0703 - factorized_top_k/top_100_categorical_accuracy: 0.0706 - loss: 15615.0811 - regularization_loss: 0.0000e+00 - total_loss: 15615.0811                    "
     ]
    }
   ],
   "source": [
    "# Train for 3 epochs.\n",
    "model.fit(listens.batch(2048), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index(songs.batch(100).map(model.song_model), songs)\n",
    "\n",
    "# Get some recommendations.\n",
    "_, titles = index(np.array([\"42\"]))\n",
    "print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27663dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = (\n",
    "#     tf.data.Dataset.from_tensor_slices(\n",
    "#         (\n",
    "#             tf.cast(df['user'].values, tf.string),\n",
    "#             tf.cast(df['song'].values, tf.string),\n",
    "#             tf.cast(df['Song - Artist'].values, tf.string),\n",
    "#             tf.cast(df['count'].values, tf.int32)\n",
    "#         )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to list\n",
    "# user_list = df['user'].to_list()\n",
    "# song_list = df['song'].to_list()\n",
    "# count_list = df['count'].to_list()\n",
    "# song_artist_list = df['Song - Artist'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf10b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert user id and song id to numerical ids\n",
    "# df['user_id'] = df['user'].astype('category').cat.codes\n",
    "# df['song_id'] = df['song'].astype('category').cat.codes\n",
    "\n",
    "# # Create lookup frame so we can get the 'Song - Artist' later\n",
    "# item_lookup = df[['song_id','Song - Artist']].drop_duplicates()\n",
    "# item_lookup['song_id'] = item_lookup['song_id'].astype(str)\n",
    "\n",
    "# # Drop 'user' and 'song' and 'Song - Artist'\n",
    "# df = df.drop(['user','song','Song - Artist'], axis=1)\n",
    "\n",
    "# df = df[['song_id','user_id','count']]\n",
    "\n",
    "# # Get number of unique entities in songs & users columns\n",
    "# nsong_id = df.song_id.nunique()\n",
    "# nuser_id = df.user_id.nunique()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3252a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
