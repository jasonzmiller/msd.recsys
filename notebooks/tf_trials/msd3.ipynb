{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ede6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3271e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./datasets/clean_df.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user id and song id to numerical ids\n",
    "df['user_id'] = df['user'].astype('category').cat.codes\n",
    "df['song_id'] = df['song'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lookup frame so we can get the 'Song - Artist' later\n",
    "item_lookup = df[['song_id','Song - Artist']].drop_duplicates()\n",
    "item_lookup['song_id'] = item_lookup['song_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'user' and 'song' and 'Song - Artist'\n",
    "df = df.drop(['user','song','Song - Artist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09986f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of all users, songs, and counts\n",
    "users = list(np.sort(df['user_id'].unique()))\n",
    "songs = list(np.sort(df['song_id'].unique()))\n",
    "play_counts = list(np.sort(df['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows and columns for our matrix\n",
    "rows = df['user_id'].astype(float)\n",
    "cols = df['song_id'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sparse = sp.csr_matrix((play_counts, (rows, cols)), shape=(len(users), len(songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "uids, iids = data_sparse.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcc277",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batches = 30\n",
    "num_factors = 64 # Number of latent features\n",
    "\n",
    "# Independent lambda regularization values \n",
    "# for user, items and bias.\n",
    "lambda_user = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "lambda_bias = 0.0000001\n",
    "\n",
    "# Our learning rate \n",
    "lr = 0.005\n",
    "\n",
    "# How many (u,i,j) triplets we sample for each batch\n",
    "samples = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16cab7f",
   "metadata": {},
   "source": [
    "Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "def init_variable(size, dim, name=None):\n",
    "    '''\n",
    "    Helper function to initialize a new variable with\n",
    "    uniform random values.\n",
    "    '''\n",
    "    std = np.sqrt(2 / dim)\n",
    "    return tf.Variable(tf.random_uniform([size, dim], -std, std), name=name)\n",
    "\n",
    "\n",
    "def embed(inputs, size, dim, name=None):\n",
    "    '''\n",
    "    Helper function to get a Tensorflow variable and create\n",
    "    an embedding lookup to map our user and item\n",
    "    indices to vectors.\n",
    "    '''\n",
    "    emb = init_variable(size, dim, name)\n",
    "    return tf.nn.embedding_lookup(emb, inputs)\n",
    "\n",
    "\n",
    "def get_variable(graph, session, name):\n",
    "    '''\n",
    "    Helper function to get the value of a\n",
    "    Tensorflow variable by name.\n",
    "    '''\n",
    "    v = graph.get_operation_by_name(name)\n",
    "    v = v.values()[0]\n",
    "    v = v.eval(session=session)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84298100",
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    '''\n",
    "    Loss function: \n",
    "    -SUM ln σ(xui - xuj) + λ(w1)**2 + λ(w2)**2 + λ(w3)**2 ...\n",
    "    ln = the natural log\n",
    "    σ(xuij) = the sigmoid function of xuij.\n",
    "    λ = lambda regularization value.\n",
    "    ||W||**2 = the squared L2 norm of our model parameters.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Input into our model, in this case our user (u),\n",
    "    # known item (i) an unknown item (i) triplets.\n",
    "    u = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    i = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    j = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "\n",
    "    # User feature embedding\n",
    "    u_factors = embed(u, len(users), num_factors, 'user_factors') # U matrix\n",
    "\n",
    "    # Known and unknown item embeddings\n",
    "    item_factors = init_variable(len(artists), num_factors, \"item_factors\") # V matrix\n",
    "    i_factors = tf.nn.embedding_lookup(item_factors, i)\n",
    "    j_factors = tf.nn.embedding_lookup(item_factors, j)\n",
    "\n",
    "    # i and j bias embeddings.\n",
    "    item_bias = init_variable(len(artists), 1, \"item_bias\")\n",
    "    i_bias = tf.nn.embedding_lookup(item_bias, i)\n",
    "    i_bias = tf.reshape(i_bias, [-1, 1])\n",
    "    j_bias = tf.nn.embedding_lookup(item_bias, j)\n",
    "    j_bias = tf.reshape(j_bias, [-1, 1])\n",
    "\n",
    "    # Calculate the dot product + bias for known and unknown\n",
    "    # item to get xui and xuj.\n",
    "    xui = i_bias + tf.reduce_sum(u_factors * i_factors, axis=2)\n",
    "    xuj = j_bias + tf.reduce_sum(u_factors * j_factors, axis=2)\n",
    "\n",
    "    # We calculate xuij.\n",
    "    xuij = xui - xuj\n",
    "\n",
    "    # Calculate the mean AUC (area under curve).\n",
    "    # if xuij is greater than 0, that means that \n",
    "    # xui is greater than xuj (and thats what we want).\n",
    "    u_auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "    # Output the AUC value to tensorboard for monitoring.\n",
    "    tf.summary.scalar('auc', u_auc)\n",
    "\n",
    "    # Calculate the squared L2 norm ||W||**2 multiplied by λ.\n",
    "    l2_norm = tf.add_n([\n",
    "        lambda_user * tf.reduce_sum(tf.multiply(u_factors, u_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(i_factors, i_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(j_factors, j_factors)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(i_bias, i_bias)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(j_bias, j_bias))\n",
    "        ])\n",
    "\n",
    "    # Calculate the loss as ||W||**2 - ln σ(Xuij)\n",
    "    #loss = l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(xuij)))\n",
    "    loss = -tf.reduce_mean(tf.log(tf.sigmoid(xuij))) + l2_norm\n",
    "    \n",
    "    # Train using the Adam optimizer to minimize \n",
    "    # our loss function.\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    step = opt.minimize(loss)\n",
    "\n",
    "    # Initialize all tensorflow variables.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514b349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
