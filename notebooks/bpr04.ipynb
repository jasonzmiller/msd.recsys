{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3a6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ad6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../datasets/clean_df.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43f314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user id and song id to numerical ids\n",
    "df['user_id'] = df['user'].astype('category').cat.codes\n",
    "df['song_id'] = df['song'].astype('category').cat.codes\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Create lookup frame so we can get the 'Song - Artist' later\n",
    "item_lookup = df[['song_id','Song - Artist']].drop_duplicates()\n",
    "item_lookup['song_id'] = item_lookup['song_id'].astype(str)\n",
    "\n",
    "# Drop 'user' and 'song' and 'Song - Artist'\n",
    "df = df.drop(['user','song','Song - Artist'], axis=1)\n",
    "\n",
    "df = df.sort_values(by=['user_id', 'song_id'])\n",
    "\n",
    "aggd = df.groupby('user_id')['song_id'].agg(list).reset_index()\n",
    "nuser_listens = {row['user_id'] : row['song_id'] for _ , row in aggd.iterrows()}\n",
    "\n",
    "# Create lists of all unique users, songs\n",
    "uusers = list(np.sort(df['user_id'].unique()))\n",
    "usongs = list(np.sort(df['song_id'].unique()))\n",
    "nusers = len(uusers)\n",
    "nsongs = len(usongs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07dbf7",
   "metadata": {},
   "source": [
    "### Validation hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abca16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418252, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_val = (\n",
    "        df.groupby('user_id')['song_id'].count()\n",
    "    ).reset_index().rename({'song_id':'records'}, axis=1)\n",
    "tmp_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921c81f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41355, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_records = 3\n",
    "conditions = df['user_id'].isin(tmp_val[tmp_val['records'] > min_records].user_id)\n",
    "df_val = df[conditions].groupby('user_id').head(1).reset_index()\n",
    "del df_val['index']\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ce0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = { row.user_id : row.song_id for _ , row in df_val.iterrows() }\n",
    "df_train = pd.concat([df, df_val]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f8a82",
   "metadata": {},
   "source": [
    "### Building Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8af0788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 418252/418252 [8:46:47<00:00, 13.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 20min 4s, sys: 12min 44s, total: 8h 32min 48s\n",
      "Wall time: 8h 46min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "n_random_samples = 2\n",
    "\n",
    "uusers_train = list(df_train['user_id'].unique())\n",
    "\n",
    "for user in tqdm( uusers_train ):\n",
    "    listened = df_train[df_train['user_id'] == user]['song_id'].values\n",
    "    \n",
    "    for i in listened:\n",
    "        cnt = 0\n",
    "        while ( cnt < n_random_samples ):\n",
    "            j = df_train.sample(1).iloc[0,2]\n",
    "            if ( j not in listened ):\n",
    "                data.append({\n",
    "                    'u' : user,\n",
    "                    'i' : i,\n",
    "                    'j' : j\n",
    "                })\n",
    "                cnt += 1\n",
    "\n",
    "ttriplets = pd.DataFrame(data, columns=['u', 'i', 'j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be3e7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttriplets.to_pickle('../datasets/ttriplets_LOCAL_PICKLE.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7c9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttriplets.to_csv('../datasets/ttriplets_LOCAL.csv', compression='zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1feb69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\n",
    "    'user_input': tf.convert_to_tensor(ttriplets.u),\n",
    "    'positive_item_input': tf.convert_to_tensor(ttriplets.i),\n",
    "    'negative_item_input': tf.convert_to_tensor(ttriplets.j)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa9e5b",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18352ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def identity_loss(_, y_pred):\n",
    "    return tf.math.reduce_mean(y_pred)\n",
    "\n",
    "@tf.function\n",
    "def triplet_loss(X: dict):\n",
    "    i_latent , j_latent , u_latent = X\n",
    "    pos_interactions = tf.math.reduce_sum(tf.math.multiply(u_latent, i_latent), axis=-1, keepdims=True)\n",
    "    neg_interactions = tf.math.reduce_sum(tf.math.multiply(u_latent, j_latent), axis=-1, keepdims=True)\n",
    "    return tf.math.subtract(tf.constant(1.0), tf.sigmoid(tf.math.subtract(pos_interactions, neg_interactions)))\n",
    "\n",
    "def out_shape(shapes):\n",
    "    return shapes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1469d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_users: int, num_items: int, latent_dim: int) -> Model:\n",
    "    u_input = Input((1,), name='user_input')\n",
    "    i_input = Input((1,), name='positive_item_input')\n",
    "    j_input = Input((1,), name='negative_item_input')\n",
    "    \n",
    "    item_emb = Embedding(num_items, latent_dim, name='item_embedding', input_length=1)\n",
    "    i_emb = Flatten()( item_emb(i_input) )\n",
    "    j_emb = Flatten()( item_emb(j_input) )\n",
    "    \n",
    "    u_emb = Embedding(num_users, latent_dim, name='user_embedding', input_length=1)(u_input)\n",
    "    u_emb = Flatten()(u_emb)\n",
    "    \n",
    "    t_loss = Lambda(triplet_loss, output_shape=out_shape, name='triplet_loss')([i_emb, j_emb, u_emb])\n",
    "    \n",
    "    model = Model(inputs=[i_input, j_input, u_input], outputs=t_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542279da",
   "metadata": {},
   "source": [
    "#### Functions used to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a950d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model: Model, song_ids: list):\n",
    "    u = model.get_layer('user_embedding').get_weights()[0]\n",
    "    i = model.get_layer('item_embedding').get_weights()[0][song_ids]\n",
    "    return u, i\n",
    "\n",
    "def get_topk(model, user, usongs, weights, k=10):\n",
    "    user_weights, item_weights = weights\n",
    "    \n",
    "    user_vector = user_weights[user]\n",
    "    item_matrix = item_weights\n",
    "    \n",
    "    scores = np.dot(user_vector, item_matrix.T)\n",
    "    \n",
    "    predictions = dict(zip(usongs,scores))\n",
    "    predictions = sorted(predictions.items(), key=lambda kv:kv[1], reverse=True)[:k]\n",
    "    predictions = list(OrderedDict(predictions).keys())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def get_hits(user_listens, user_recs):\n",
    "    hits = 0\n",
    "    for song in user_listens:\n",
    "        if ( song in user_recs ):\n",
    "            hits += 1\n",
    "    return hits\n",
    "\n",
    "def get_metrics(uusers: list, nuser_listens: dict, nuser_recs: dict, N: int, k=10):\n",
    "    nusers = len(uusers)\n",
    "    precision = recall = t_hits = 0\n",
    "    \n",
    "    for user in tqdm(uusers, desc='Getting metrics... '):\n",
    "        hits = get_hits(user_listens=nuser_listens[user], user_recs=nuser_recs[user])\n",
    "        precision += hits / len(nuser_listens[user])\n",
    "        recall += hits / k\n",
    "        t_hits += hits\n",
    "                                \n",
    "    precision = precision / nusers\n",
    "    recall = recall / nusers\n",
    "    hit_ratio = t_hits / N\n",
    "    \n",
    "    return precision, recall, hit_ratio\n",
    "\n",
    "def hold_out_hit_ratio(ground_truth: dict, nuser_recs: dict):\n",
    "    hits = 0\n",
    "    for _ , (user , song) in enumerate(ground_truth.items()):\n",
    "        if song in nuser_recs[user]:\n",
    "            hits += 0\n",
    "    return hits / (len(ground_truth) if len(ground_truth) > 0 else 1)\n",
    "\n",
    "def evaluate(model: Model, uusers: list, usongs: list, nuser_listens: dict, N: int, ground_truth=None, k=10):\n",
    "    weights = get_weights(model, usongs)\n",
    "    nuser_recs = {user : get_topk(model=model, user=user, usongs=usongs, weights=weights) for user in tqdm(uusers, desc='Generating recommendations for all users... ')}\n",
    "    p , r , hr = get_metrics(uusers=uusers, nuser_listens=nuser_listens, nuser_recs=nuser_recs, N=N)\n",
    "    hoh = hold_out_hit_ratio(ground_truth, nuser_recs)\n",
    "        \n",
    "    evals = {\n",
    "        'precision' : p,\n",
    "        'recall' : r,\n",
    "        'hit_ratio' : hr,\n",
    "        'hold_out_hits': hoh\n",
    "    }\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd81d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "#  HYPERPARAMS\n",
    "#---------------\n",
    "latent_dims = [200, 250, 300, 350]\n",
    "batch_size = 512\n",
    "epochs = 3\n",
    "learning_rates = [0.01, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3b3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "LATENT DIMENSIONS: 200. LEARNING_RATE: 0.01\n",
      "Epoch 1/3\n",
      "  40/2857 [..............................] - ETA: 1:10:00 - loss: 0.4996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-824ae296cdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnusers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsongs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentity_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#         print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muusers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muusers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musongs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musongs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnuser_listens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnuser_listens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_hist = []\n",
    "for latent_dim in latent_dims:\n",
    "    for learning_rate in learning_rates:\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        print(f'LATENT DIMENSIONS: {latent_dim}. LEARNING_RATE: {learning_rate}')\n",
    "        model = build_model(nusers, nsongs, latent_dim)\n",
    "        model.compile(loss=identity_loss, optimizer=Adam(learning_rate))\n",
    "        model.fit(X, tf.ones(ttriplets.shape[0]), batch_size, verbose=1, epochs=epochs)\n",
    "        evals = evaluate(model=model, uusers=uusers, usongs=usongs, nuser_listens=nuser_listens, ground_truth=ground_truth, N=df.shape[0])\n",
    "        print(evals)\n",
    "        model_hist.append({\n",
    "            'latent_dim' : latent_dim,\n",
    "            'learning_rate' : learning_rate,\n",
    "            'precision' : evals['precision'],\n",
    "            'recall' : evals['recall'],\n",
    "            'hit_ratio' : evals['hit_ratio'],\n",
    "            'hold_out_hits' : evals['hold_out_hits']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca717531",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    {\n",
    "        'latent_dim' : 200,\n",
    "        'learning_rate' : 0.001,\n",
    "        'precision' : 0.9007733868363252,\n",
    "        'recall' : 0.1580288916722781,\n",
    "        'hit_ratio' : 0.85543207176239,\n",
    "        'hold_out_hits' : 0.0\n",
    "    },\n",
    "    {\n",
    "        'latent_dim' : 200,\n",
    "        'learning_rate' : 0.01,\n",
    "        'precision' : 0.965031453031885,\n",
    "        'recall' : 0.1688926771415658,\n",
    "        'hit_ratio' : 0.9142392329883351,\n",
    "        'hold_out_hits' : 0.0\n",
    "    },\n",
    "    {\n",
    "        'latent_dim' : 200,\n",
    "        'learning_rate' : 0.1,\n",
    "        'precision' : 0.6523921812302971,\n",
    "        'recall' : 0.09435077417386167,\n",
    "        'hit_ratio' : 0.5107336852772432,\n",
    "        'hold_out_hits' : 0.0\n",
    "    },\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a099a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latent_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>hit_ratio</th>\n",
       "      <th>hold_out_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.900773</td>\n",
       "      <td>0.158029</td>\n",
       "      <td>0.855432</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.965031</td>\n",
       "      <td>0.168893</td>\n",
       "      <td>0.914239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.652392</td>\n",
       "      <td>0.094351</td>\n",
       "      <td>0.510734</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latent_dim  learning_rate  precision    recall  hit_ratio  hold_out_hits\n",
       "0         200          0.001   0.900773  0.158029   0.855432            0.0\n",
       "1         200          0.010   0.965031  0.168893   0.914239            0.0\n",
       "2         200          0.100   0.652392  0.094351   0.510734            0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca9701bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_results['learning_rate'], df_results['recall'])\n",
    "# plt.title('Latent Dimensions')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82267ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
